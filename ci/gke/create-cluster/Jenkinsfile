pipeline {
    agent any
    environment {
        JENKINS_CREDENTIALS_ID = "sa-gcloud"
        CONTAINER_IMAGE = "gcr.io/google.com/cloudsdktool/cloud-sdk"
        CREDENTIALS_BUCKET = "gs://sa-credentials-a094929"
        VARS_BUCKET = "gs://terraform-vars-a094929"
        MODULE_FOLDER = "clusters/gke"
        MODULE_ROOT = "$WORKSPACE/terraform/$MODULE_FOLDER"
    }
    stages {

        stage("clone source") {
            steps {
                cleanWs()
                // TODO consider replacing with [checkout scm] as described here: https://support.cloudbees.com/hc/en-us/articles/226122247-How-to-Customize-Checkout-for-Pipeline-Multibranch-
                git branch: "main", url: "https://github.com/pacphi/docker-terraform-and-jenkins.git"
            }
        }

        stage("copy scripts into terraform module") {
            steps {
                sh("cp $WORKSPACE/bin/*.sh $MODULE_ROOT")
            }
        }

        stage("fetch sensitive configuration") {
            steps {
                // sa-gcloud service account has only permissions to read from cloud storage buckets
                withCredentials([file(credentialsId: "$JENKINS_CREDENTIALS_ID", variable: 'JSON_KEY')]) {
                    sh('cp -f ${JSON_KEY} $MODULE_ROOT/gcp-service-account.json')
                    // emit details of container image we're employing
                    sh("docker run -i --rm $CONTAINER_IMAGE gcloud version")
                    // authentication and activation of the service account that will read (and download files) from cloud storage buckets
                    sh('docker run -i --rm --name gcloud-config -v $MODULE_ROOT:/workspace $CONTAINER_IMAGE gcloud auth activate-service-account --key-file=/workspace/gcp-service-account.json')
                    // user-supplied configuration that will drive terraform module
                    // TODO we'll want to reimagine sourcing this as a collection of pipeline parameters with defaults
                    // parameters are updated per job resulting in creation of new resources each 
                    sh("docker run -i --rm --name gcloud-config -v $MODULE_ROOT:/workspace $CONTAINER_IMAGE gsutil cp $VARS_BUCKET/$MODULE_FOLDER/terraform.tfvars /workspace")
                    // sets up where we will manage terraform state, operator defined
                    // TODO we'll want to feed the backend subpath as user-suppler configuration, so while most of the backend config is static the subpath will vary per job 
                    sh("docker run -i --rm --name gcloud-config -v $MODULE_ROOT:/workspace $CONTAINER_IMAGE gsutil cp $VARS_BUCKET/$MODULE_FOLDER/backend.tf /workspace")
                    // this service account differs from sa-gcloud in that it will have elevated permissions to create resources as defined in terraform module; overwrites prior copy of service account file
                    sh("docker run -i --rm --name gcloud-config -v $MODULE_ROOT:/workspace $CONTAINER_IMAGE gsutil cp $CREDENTIALS_BUCKET/gcp-service-account.json /workspace")
                }
            }
        }

        stage("terraform init") {
            steps {
                sh("cd $MODULE_ROOT && ./terraform-init.sh")
            }
        }

        stage("terraform plan") {
            steps {
                sh("cd $MODULE_ROOT && ./terraform-plan.sh")
            }
        }

        stage("terraform apply") {
            steps {
                sh("cd $MODULE_ROOT && ./terraform-apply.sh")
            }
        }

        stage("cleanup") {
            steps {
                // leave no trace of sensitive configuration
                sh("rm -f $MODULE_ROOT/gcp-service-account.json $MODULE_ROOT/backend.tf $MODULE_ROOT/terraform.tfvars $MODULE_ROOT/*.sh")
            }
        }
    }
}